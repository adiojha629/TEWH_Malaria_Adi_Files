{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02.27 - FSRCNN Image Upscaling",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adiojha629/TEWH_Malaria_Adi_Files/blob/master/FSRCNN_Image_Upscaling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA2uvH26swpB",
        "colab_type": "text"
      },
      "source": [
        "# Task Description: Upscaling Image Resolution with FSRCNN\n",
        "Run the code chunk below to obtain your appropriate test and train datasets. You do not need to understand the code chunk below. The next section of text will explain what the variables and characteristics of your dataset are. \n",
        "<br>\n",
        "<br>\n",
        "Your task is to develop a neural network architecture called Fast Super-Resolution Convolutonal Neural Network (FSRCNN), which is a recently developed method used to upscale low-resolution images into high-resolution images. Your task will to upscale downsampled images that 32x32 pixels into high resolution images that are 128x128 pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h72VqJwYafQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "outputId": "d240619b-1a5c-4b89-80d7-73a5d619ff03"
      },
      "source": [
        "# Import relevant packages\n",
        "import numpy as np\n",
        "import os\n",
        "from shutil import copyfile\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# Download NIH dataset zip file\n",
        "!wget -nc ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip\n",
        "\n",
        "# Extract images if not already extracted\n",
        "ROOT_DIR = os.path.join(\"/\", \"content\")\n",
        "if not os.path.isdir(\"cell_images\"):\n",
        "    print(\"Extracting images...\")\n",
        "    with ZipFile(os.path.join(\"cell_images.zip\"), \"r\") as zipObj:\n",
        "        zipObj.extractall()\n",
        "    print(\"Done!\")\n",
        "\n",
        "# Install and import relevant packages\n",
        "import numpy as np\n",
        "import os\n",
        "!pip install opencv-python\n",
        "!apt update && apt install -y libsm6 libxext6 libxrender1\n",
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "# Create new folders to save rescaled images\n",
        "if not os.path.isdir(\"RescaledSet\"):\n",
        "    os.mkdir(\"RescaledSet\")\n",
        "if not os.path.isdir(\"RescaledSet/Parasitized\"):\n",
        "    os.mkdir(\"RescaledSet/Parasitized\")\n",
        "if not os.path.isdir(\"RescaledSet/Uninfected\"):\n",
        "    os.mkdir(\"RescaledSet/Uninfected\")\n",
        "\n",
        "# Generate list of parasitized file names\n",
        "ParasitizedFiles = os.listdir(\"cell_images/Parasitized/\")\n",
        "UninfectedFiles = os.listdir(\"cell_images/Uninfected/\")\n",
        "\n",
        "# Remove Thumb.db files\n",
        "while 'Thumbs.db' in ParasitizedFiles: ParasitizedFiles.remove('Thumbs.db')   \n",
        "while 'Thumbs.db' in UninfectedFiles: UninfectedFiles.remove('Thumbs.db')  \n",
        "\n",
        "# Pre-allocate memory space for images\n",
        "Parasitized = np.empty([2500,128,128,3])\n",
        "Uninfected = np.empty([2500,128,128,3])\n",
        "\n",
        "# Resize and load parasitized images\n",
        "for i in range(2500):\n",
        "    TempImage = cv2.imread('cell_images/Parasitized/'+ParasitizedFiles[i])\n",
        "    ResizedImage = cv2.resize(TempImage, dsize=(128,128))\n",
        "    Parasitized[i,:,:,:] = ResizedImage\n",
        "\n",
        "# Resize and load uninfected images\n",
        "for i in range(2500):\n",
        "    TempImage = cv2.imread('cell_images/Uninfected/'+UninfectedFiles[i])\n",
        "    ResizedImage = cv2.resize(TempImage, dsize=(128,128))\n",
        "    Uninfected[i,:,:,:] = ResizedImage\n",
        "    \n",
        "print('Uninfected Dataset size is:',np.shape(Uninfected))\n",
        "print('Parasitized Dataset size is:',np.shape(Parasitized))\n",
        "\n",
        "# Generate dataset labels\n",
        "ParasitizedLabels = np.repeat([[0,1]], 2500, axis=0)\n",
        "UninfectedLabels = np.repeat([[1,0]], 2500, axis=0)\n",
        "Labels = np.concatenate((ParasitizedLabels,UninfectedLabels), axis=0)\n",
        "\n",
        "# Generate image dataset\n",
        "Dataset = np.concatenate((Parasitized, Uninfected), axis=0)\n",
        "\n",
        "# Generate 5-fold cross-validation groups\n",
        "CVIndices = np.random.permutation(Dataset.shape[0])\n",
        "TrainInd, TestInd = CVIndices[:4000], CVIndices[4000:]\n",
        "\n",
        "# Generate train and test sets\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "\n",
        "TrainOut = Dataset[TrainInd,:]\n",
        "TestOut = Dataset[TestInd,:]\n",
        "TrainIn = np.zeros([np.shape(TrainOut)[0],32,32,3])\n",
        "TestIn = np.zeros([np.shape(TestOut)[0],32,32,3])\n",
        "for i in range(np.shape(TrainOut)[0]):\n",
        "  TrainIn[i,:,:,:] = downscale_local_mean(TrainOut[i,:,:,:], (4,4,1))\n",
        "for i in range(np.shape(TestOut)[0]):\n",
        "  TestIn[i,:,:,:] = downscale_local_mean(TestOut[i,:,:,:], (4,4,1))\n",
        "\n",
        "# Delete large irrelevant variables to minimize RAM usage\n",
        "del Dataset\n",
        "del Parasitized\n",
        "del Uninfected"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-14 17:29:22--  ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip\n",
            "           => ‘cell_images.zip’\n",
            "Resolving lhcftp.nlm.nih.gov (lhcftp.nlm.nih.gov)... 130.14.55.35, 2607:f220:41e:7055::35\n",
            "Connecting to lhcftp.nlm.nih.gov (lhcftp.nlm.nih.gov)|130.14.55.35|:21... connected.\n",
            "Logging in as anonymous ... Logged in!\n",
            "==> SYST ... done.    ==> PWD ... done.\n",
            "==> TYPE I ... done.  ==> CWD (1) /Open-Access-Datasets/Malaria ... done.\n",
            "==> SIZE cell_images.zip ... 353452851\n",
            "==> PASV ... done.    ==> RETR cell_images.zip ... done.\n",
            "Length: 353452851 (337M) (unauthoritative)\n",
            "\n",
            "cell_images.zip     100%[===================>] 337.08M  73.9MB/s    in 4.8s    \n",
            "\n",
            "2020-03-14 17:29:32 (70.5 MB/s) - ‘cell_images.zip’ saved [353452851]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-144df69fa15d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Download NIH dataset zip file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget -nc ftp://lhcftp.nlm.nih.gov/Open-Access-Datasets/Malaria/cell_images.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Extract images if not already extracted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXWu7fSSnPOg",
        "colab_type": "text"
      },
      "source": [
        "# Overview of Variables to Work With\n",
        "After running the previous code chunk, you should have four variables listed below. Note that the 1st dimension in these NumPy arrays are the number of images, while the 2nd and 3rd dimensions are the pixel resolutions. Lastly, the 4th dimension is the number of channels (RGB images have 3 channels). \n",
        "\n",
        "- ```TrainIn```: This variable contains 4000 images that have been downsampled from 128x128 pixels to 32x32 pixels. This is what will be used to train the neural network architecture.\n",
        "- ```TrainOut```: This variable contains the corresponding original 4000 images that are 128x128 pixels (ie. not downsampled).\n",
        "- ```TestIn```: This will be the testing set containing 1000 images that have been downsampled to 32x32 pixels.\n",
        "- ```TestOut```: This will be the testing set containing the corresponding original 1000 images that have not been downsampled. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1GDb_5anzAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "f8c66e64-dbb0-45b9-840a-cb254b305181"
      },
      "source": [
        "print('The dimensions of the training inputs are:',np.shape(TrainIn))\n",
        "print('The dimensions of the training outputs are:',np.shape(TrainOut))\n",
        "print('The dimensions of the testing inputs are:',np.shape(TestIn))\n",
        "print('The dimensions of the testing outputs are:',np.shape(TestOut))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dimensions of the training inputs are: (4000, 32, 32, 3)\n",
            "The dimensions of the training outputs are: (4000, 128, 128, 3)\n",
            "The dimensions of the testing inputs are: (1000, 32, 32, 3)\n",
            "The dimensions of the testing outputs are: (1000, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7zhMPCJezDm",
        "colab_type": "text"
      },
      "source": [
        "# Fast Super-Resolution Convolutional Neural Network (FSRCNN)\n",
        "\n",
        "## Background\n",
        "The Fast Super-Resolution Convolutoinal Neural Network (FSRCNN) was recently developed in just 2016 by a group of data scientists in Hong Kong (https://arxiv.org/pdf/1608.00367.pdf), and since then has received over 800 citations. Less than 0.01% of published papers have over 1000 citations. Point is? FSRCNN was a huge deal at the time. Key phrase: at the time. Despite it the young age of FSRCNN, it has already been widely replaced by other more advanced methods due to the rapidly growing field of deep learning (as per usual). \n",
        "<br>\n",
        "<br>\n",
        "With that being said, FSRCNN is the perfect neural network model to serve as a baseline for upscaling image resolution. It is also simple enough that creating and training this model will serve as a critical exercise before you guys move on to more advanced architectures. In the figure below, the SRCNN is the original predecessor of the FSRCNN, which as you see is just a simple three-layered convolutional neural network. FSRCNN is both faster, smaller, and more effective than SRCNN in virtually all scenarios, which is why we do not bother testing out SRCNN. The architecture you guys are interested in re-creating is the one shown in the second row in the figure below.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=16e1QmIPJmvSLiKrcraLrxsJlX_a3lPkT)\n",
        "\n",
        "We see that the FSRCNN architecture can be split into five general sections, described below:\n",
        "\n",
        "- **Feature Extraction**: This part consists of a single convolutional layer with a 5x5 filter and a somewhat arbitrarily chosen number of filters. For now, create this layer with *d* = 56 filters. This layer essentially extracts valuable features from the low-resolution image that will be used later on to re-create the high-resolution image.\n",
        "- **Shrinking**: In this step, we use a 1x1 convolutional filter to shrink that high feature dimension (*d* = 56) of the LR image into a low feature dimension (*s* = 16) of the HR image. This allows us to greatly reduce the number of parameters, hence resulting in a leaner and faster model.\n",
        "- **Non-Linear Mapping**: In this section, we use a somewhat arbitrarily chosen number of identical 3x3 convolution layers with *s* = 12 filters. This section is the most influential part of the FSRCNN performance. A higher number of mapping layers allows for a higher level of feature complexity. Since our images are relatively simple, we shall only use four mapping layers. \n",
        "- **Expanding**: This section can be interpretted in some ways, as the opposite of the shrinking section. After creating non-linear mapping relationships, we expand the HR feature dimension back to a high number of features to allow for a clearer HR image. We use a 1x1 convolutional layer with back to the original *d* = 56 filters to go back to a high feature dimension.\n",
        "- **Deconvolution**: This last section upsamples and aggregates the high feature dimensions generated by the previous expanding section. We use a 9x9 filter, with the number of filters equal to the number of image channels. Since our images are in RGB, we use 3 filters, one for each color channel. The stride length determines the upscaling factor of the image. Since in our case, we want to upscale an image from 32x32 to 128x128 - a factor of 4x - we want ```stride_length = (4,4)```. \n",
        "<br>\n",
        "<br>\n",
        "For ALL layers, we will implement zero padding so that the image dimensions remain the same up until the deconvolution layer, in which upscaling occurs. In addition, the activation function to be used will be parametric ReLU, which is similar to a ReLU function, except that the negative output is a trainable slope, rather than 0, as shown in the image below. \n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1qUZFlIBn2_aPnT6pdFxIhfbId6CbSOLI)\n",
        "\n",
        "In the code chunk below, we created a single convolution and deconvolution layer for demonstration, so that you guys may build the full model. In the ```Conv2D()``` function, there are several arguments:\n",
        "\n",
        "- ```filters```: Specifies the number of filters to use\n",
        "- ```kernel_size```: Specifies the size of the filters\n",
        "- ```strides```: Specifies the stride of the filter. Default setting is (1,1)\n",
        "- ```padding```: Set ```padding = 'same'``` for zero padding. \n",
        "- ```activation```: specifies activation function, if you do not specify one, you can specify it in the next layer, which is what was done in the example below with ```PRelu()```. \n",
        "- ```kernel_initializer```: How to randomize the weights. For this, just set ```kernel_initializer = 'he_normal'``` for all layers, as shown in the example below.\n",
        "<br>\n",
        "<br>\n",
        "In the code chunk below, I already written the model compilation section for you. You can tweak it as desired (eg. changing optimizer, learning rate, batch size, epochs, etc). The most important thing here is creating the architecture itself though. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeedIDeOpWG6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "outputId": "33d2f513-9c06-4bd2-e008-55111152c52c"
      },
      "source": [
        "## Create FSRCNN architecture\n",
        "from keras import optimizers\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, Input, ZeroPadding2D, Conv2DTranspose, merge \n",
        "from keras.layers.advanced_activations import PReLU\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#Feature Extraction\n",
        "model = Sequential()\n",
        "input_img = Input(shape=(32,32,3))\n",
        "model = Conv2D(filters = 56, kernel_size = (5, 5), padding='same', kernel_initializer='he_normal')(input_img)\n",
        "model = PReLU()(model)\n",
        "\n",
        "#Shrink\n",
        "model = Conv2D(filters = 16, kernel_size = (1, 1), padding='same', kernel_initializer='he_normal')(model)\n",
        "model = PReLU()(model)\n",
        "\n",
        "#Mapping\n",
        "model = Conv2D(filters = 12, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "model = PReLU()(model)\n",
        "model = Conv2D(filters = 12, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "model = PReLU()(model)\n",
        "model = Conv2D(filters = 12, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "model = PReLU()(model)\n",
        "model = Conv2D(filters = 12, kernel_size = (3, 3), padding='same', kernel_initializer='he_normal')(model)\n",
        "model = PReLU()(model)\n",
        "\n",
        "#Exapansion\n",
        "model = Conv2D(filters = 56, kernel_size = (1, 1), padding='same', kernel_initializer='he_normal')(model)\n",
        "model = PReLU()(model)\n",
        "\n",
        "#Deconvolution\n",
        "model = Conv2DTranspose(filters = 3, kernel_size = (9, 9), strides=(4, 4), padding='same')(model)\n",
        "output_img = model\n",
        "\n",
        "model = Model(input_img, output_img) #Create the model object\n",
        "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False) #Training optimizer\n",
        "model.compile(loss = \"mean_squared_error\", optimizer = adam, metrics=[\"mean_squared_error\"]) #How we measure error\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4479: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 56)        4256      \n",
            "_________________________________________________________________\n",
            "p_re_lu_1 (PReLU)            (None, 32, 32, 56)        57344     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 16)        912       \n",
            "_________________________________________________________________\n",
            "p_re_lu_2 (PReLU)            (None, 32, 32, 16)        16384     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 12)        1740      \n",
            "_________________________________________________________________\n",
            "p_re_lu_3 (PReLU)            (None, 32, 32, 12)        12288     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 12)        1308      \n",
            "_________________________________________________________________\n",
            "p_re_lu_4 (PReLU)            (None, 32, 32, 12)        12288     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 32, 32, 12)        1308      \n",
            "_________________________________________________________________\n",
            "p_re_lu_5 (PReLU)            (None, 32, 32, 12)        12288     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 32, 32, 12)        1308      \n",
            "_________________________________________________________________\n",
            "p_re_lu_6 (PReLU)            (None, 32, 32, 12)        12288     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 32, 32, 56)        728       \n",
            "_________________________________________________________________\n",
            "p_re_lu_7 (PReLU)            (None, 32, 32, 56)        57344     \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 128, 128, 3)       13611     \n",
            "=================================================================\n",
            "Total params: 205,395\n",
            "Trainable params: 205,395\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI9sYJMktevP",
        "colab_type": "text"
      },
      "source": [
        "## Training the FSRCNN Model\n",
        "Now we use the ```model.fit()``` function to train our neural network. Note the following arguments:\n",
        "\n",
        "- ```x```: This is the input features, which in this case is ```x = TrainIn```.\n",
        "- ```y```: This is the output features, which in this case is ```y = TrainOut```.\n",
        "- ```validation_data```: This is the testing set, which in this case is ```validation_data = (TestIn,TestOut)```.\n",
        "- ```epochs```: Specifies the number of epochs to run. Try using 100 epochs.\n",
        "- ```batch_size```: Specifies the batch size, which is the number of samples used to compute the gradient for weight updates. Try using 32.\n",
        "- ```validation_freq```: Specifies how often to use the test set. Set ```validation_freq = 1``` so that it tests the model on the test set for every 1 epoch. \n",
        "\n",
        "## Evaluating the Performance of the FSRCNN Model\n",
        "The ```model.predict()``` function simply takes in the test dataset, which in this case is ```TestIn```, and returns the output ```ModelOut```, which contains the 4D NumPy array containing the upscaled images. This is what you will use to calculate the MSE and PSNR later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdogRNPWtbXm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd1382d9-49f8-4f59-b82b-e0a80bc06b2c"
      },
      "source": [
        "Results = model.fit(y=TrainOut, x=TrainIn, validation_data = (TestIn,TestOut), epochs=100, batch_size = 32, validation_freq=1)\n",
        "\n",
        "ModelOut = model.predict(TestIn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 4000 samples, validate on 1000 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "4000/4000 [==============================] - 17s 4ms/step - loss: 1858.8184 - mean_squared_error: 1858.8184 - val_loss: 514.2066 - val_mean_squared_error: 514.2066\n",
            "Epoch 2/100\n",
            "4000/4000 [==============================] - 2s 569us/step - loss: 389.0431 - mean_squared_error: 389.0431 - val_loss: 309.1778 - val_mean_squared_error: 309.1778\n",
            "Epoch 3/100\n",
            "4000/4000 [==============================] - 2s 569us/step - loss: 276.7609 - mean_squared_error: 276.7609 - val_loss: 252.8007 - val_mean_squared_error: 252.8007\n",
            "Epoch 4/100\n",
            "4000/4000 [==============================] - 2s 571us/step - loss: 238.2954 - mean_squared_error: 238.2954 - val_loss: 226.4367 - val_mean_squared_error: 226.4367\n",
            "Epoch 5/100\n",
            "4000/4000 [==============================] - 2s 568us/step - loss: 217.0480 - mean_squared_error: 217.0480 - val_loss: 208.4104 - val_mean_squared_error: 208.4104\n",
            "Epoch 6/100\n",
            "4000/4000 [==============================] - 2s 554us/step - loss: 201.9936 - mean_squared_error: 201.9936 - val_loss: 196.5966 - val_mean_squared_error: 196.5966\n",
            "Epoch 7/100\n",
            "4000/4000 [==============================] - 2s 555us/step - loss: 191.4564 - mean_squared_error: 191.4564 - val_loss: 187.0962 - val_mean_squared_error: 187.0962\n",
            "Epoch 8/100\n",
            "4000/4000 [==============================] - 2s 552us/step - loss: 182.9524 - mean_squared_error: 182.9524 - val_loss: 179.7823 - val_mean_squared_error: 179.7823\n",
            "Epoch 9/100\n",
            "4000/4000 [==============================] - 2s 554us/step - loss: 176.5100 - mean_squared_error: 176.5100 - val_loss: 173.2920 - val_mean_squared_error: 173.2920\n",
            "Epoch 10/100\n",
            "4000/4000 [==============================] - 2s 555us/step - loss: 171.2799 - mean_squared_error: 171.2799 - val_loss: 169.5948 - val_mean_squared_error: 169.5948\n",
            "Epoch 11/100\n",
            "4000/4000 [==============================] - 2s 557us/step - loss: 165.1994 - mean_squared_error: 165.1994 - val_loss: 167.5423 - val_mean_squared_error: 167.5423\n",
            "Epoch 12/100\n",
            "4000/4000 [==============================] - 2s 557us/step - loss: 161.1450 - mean_squared_error: 161.1450 - val_loss: 160.4859 - val_mean_squared_error: 160.4859\n",
            "Epoch 13/100\n",
            "4000/4000 [==============================] - 2s 555us/step - loss: 157.2937 - mean_squared_error: 157.2937 - val_loss: 154.6294 - val_mean_squared_error: 154.6294\n",
            "Epoch 14/100\n",
            "4000/4000 [==============================] - 2s 561us/step - loss: 153.9837 - mean_squared_error: 153.9837 - val_loss: 151.4776 - val_mean_squared_error: 151.4776\n",
            "Epoch 15/100\n",
            "4000/4000 [==============================] - 2s 554us/step - loss: 149.2399 - mean_squared_error: 149.2399 - val_loss: 149.1626 - val_mean_squared_error: 149.1626\n",
            "Epoch 16/100\n",
            "4000/4000 [==============================] - 2s 558us/step - loss: 145.4053 - mean_squared_error: 145.4053 - val_loss: 146.0711 - val_mean_squared_error: 146.0711\n",
            "Epoch 17/100\n",
            "4000/4000 [==============================] - 2s 557us/step - loss: 151.4810 - mean_squared_error: 151.4810 - val_loss: 142.3416 - val_mean_squared_error: 142.3416\n",
            "Epoch 18/100\n",
            "4000/4000 [==============================] - 2s 556us/step - loss: 139.2097 - mean_squared_error: 139.2097 - val_loss: 139.7615 - val_mean_squared_error: 139.7615\n",
            "Epoch 19/100\n",
            "4000/4000 [==============================] - 2s 554us/step - loss: 137.4223 - mean_squared_error: 137.4223 - val_loss: 138.1241 - val_mean_squared_error: 138.1241\n",
            "Epoch 20/100\n",
            "4000/4000 [==============================] - 2s 557us/step - loss: 136.2873 - mean_squared_error: 136.2873 - val_loss: 138.7012 - val_mean_squared_error: 138.7012\n",
            "Epoch 21/100\n",
            "4000/4000 [==============================] - 2s 559us/step - loss: 135.1892 - mean_squared_error: 135.1892 - val_loss: 134.1222 - val_mean_squared_error: 134.1222\n",
            "Epoch 22/100\n",
            "4000/4000 [==============================] - 2s 560us/step - loss: 133.3184 - mean_squared_error: 133.3184 - val_loss: 132.9945 - val_mean_squared_error: 132.9945\n",
            "Epoch 23/100\n",
            "4000/4000 [==============================] - 2s 558us/step - loss: 130.1479 - mean_squared_error: 130.1479 - val_loss: 134.3149 - val_mean_squared_error: 134.3149\n",
            "Epoch 24/100\n",
            "4000/4000 [==============================] - 2s 555us/step - loss: 128.6461 - mean_squared_error: 128.6461 - val_loss: 139.1843 - val_mean_squared_error: 139.1843\n",
            "Epoch 25/100\n",
            "4000/4000 [==============================] - 2s 559us/step - loss: 127.6506 - mean_squared_error: 127.6506 - val_loss: 130.4679 - val_mean_squared_error: 130.4679\n",
            "Epoch 26/100\n",
            "4000/4000 [==============================] - 2s 554us/step - loss: 125.4905 - mean_squared_error: 125.4905 - val_loss: 128.4277 - val_mean_squared_error: 128.4277\n",
            "Epoch 27/100\n",
            "4000/4000 [==============================] - 2s 551us/step - loss: 123.7914 - mean_squared_error: 123.7914 - val_loss: 127.1170 - val_mean_squared_error: 127.1170\n",
            "Epoch 28/100\n",
            "4000/4000 [==============================] - 2s 556us/step - loss: 123.8554 - mean_squared_error: 123.8554 - val_loss: 150.5481 - val_mean_squared_error: 150.5481\n",
            "Epoch 29/100\n",
            "4000/4000 [==============================] - 2s 557us/step - loss: 121.1550 - mean_squared_error: 121.1550 - val_loss: 121.6550 - val_mean_squared_error: 121.6550\n",
            "Epoch 30/100\n",
            "4000/4000 [==============================] - 2s 555us/step - loss: 120.5735 - mean_squared_error: 120.5735 - val_loss: 121.0881 - val_mean_squared_error: 121.0881\n",
            "Epoch 31/100\n",
            "4000/4000 [==============================] - 2s 556us/step - loss: 117.9890 - mean_squared_error: 117.9890 - val_loss: 124.1605 - val_mean_squared_error: 124.1605\n",
            "Epoch 32/100\n",
            "4000/4000 [==============================] - 2s 567us/step - loss: 117.7986 - mean_squared_error: 117.7986 - val_loss: 120.8436 - val_mean_squared_error: 120.8436\n",
            "Epoch 33/100\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 117.8113 - mean_squared_error: 117.8113 - val_loss: 116.8400 - val_mean_squared_error: 116.8400\n",
            "Epoch 34/100\n",
            "4000/4000 [==============================] - 2s 577us/step - loss: 115.9504 - mean_squared_error: 115.9504 - val_loss: 120.4785 - val_mean_squared_error: 120.4785\n",
            "Epoch 35/100\n",
            "4000/4000 [==============================] - 2s 581us/step - loss: 115.8120 - mean_squared_error: 115.8120 - val_loss: 121.2534 - val_mean_squared_error: 121.2534\n",
            "Epoch 36/100\n",
            "4000/4000 [==============================] - 2s 581us/step - loss: 112.2219 - mean_squared_error: 112.2219 - val_loss: 113.9970 - val_mean_squared_error: 113.9970\n",
            "Epoch 37/100\n",
            "4000/4000 [==============================] - 2s 582us/step - loss: 112.0816 - mean_squared_error: 112.0816 - val_loss: 113.9124 - val_mean_squared_error: 113.9124\n",
            "Epoch 38/100\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 111.5451 - mean_squared_error: 111.5451 - val_loss: 116.2900 - val_mean_squared_error: 116.2900\n",
            "Epoch 39/100\n",
            "4000/4000 [==============================] - 2s 587us/step - loss: 114.1080 - mean_squared_error: 114.1080 - val_loss: 112.0221 - val_mean_squared_error: 112.0221\n",
            "Epoch 40/100\n",
            "4000/4000 [==============================] - 2s 586us/step - loss: 107.8763 - mean_squared_error: 107.8763 - val_loss: 112.2390 - val_mean_squared_error: 112.2390\n",
            "Epoch 41/100\n",
            "4000/4000 [==============================] - 2s 580us/step - loss: 109.3977 - mean_squared_error: 109.3977 - val_loss: 110.7564 - val_mean_squared_error: 110.7564\n",
            "Epoch 42/100\n",
            "4000/4000 [==============================] - 2s 577us/step - loss: 108.6884 - mean_squared_error: 108.6884 - val_loss: 109.8124 - val_mean_squared_error: 109.8124\n",
            "Epoch 43/100\n",
            "4000/4000 [==============================] - 2s 577us/step - loss: 107.0152 - mean_squared_error: 107.0152 - val_loss: 108.5954 - val_mean_squared_error: 108.5954\n",
            "Epoch 44/100\n",
            "4000/4000 [==============================] - 2s 572us/step - loss: 106.0221 - mean_squared_error: 106.0221 - val_loss: 108.3811 - val_mean_squared_error: 108.3811\n",
            "Epoch 45/100\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 106.1743 - mean_squared_error: 106.1743 - val_loss: 109.1884 - val_mean_squared_error: 109.1884\n",
            "Epoch 46/100\n",
            "4000/4000 [==============================] - 2s 603us/step - loss: 107.3702 - mean_squared_error: 107.3702 - val_loss: 107.5806 - val_mean_squared_error: 107.5806\n",
            "Epoch 47/100\n",
            "4000/4000 [==============================] - 2s 599us/step - loss: 103.8316 - mean_squared_error: 103.8316 - val_loss: 107.2807 - val_mean_squared_error: 107.2807\n",
            "Epoch 48/100\n",
            "4000/4000 [==============================] - 2s 583us/step - loss: 103.4514 - mean_squared_error: 103.4514 - val_loss: 106.0323 - val_mean_squared_error: 106.0323\n",
            "Epoch 49/100\n",
            "4000/4000 [==============================] - 2s 585us/step - loss: 110.6733 - mean_squared_error: 110.6733 - val_loss: 105.7480 - val_mean_squared_error: 105.7480\n",
            "Epoch 50/100\n",
            "4000/4000 [==============================] - 2s 579us/step - loss: 100.9549 - mean_squared_error: 100.9549 - val_loss: 104.5807 - val_mean_squared_error: 104.5807\n",
            "Epoch 51/100\n",
            "4000/4000 [==============================] - 2s 580us/step - loss: 101.4976 - mean_squared_error: 101.4976 - val_loss: 106.1228 - val_mean_squared_error: 106.1228\n",
            "Epoch 52/100\n",
            "4000/4000 [==============================] - 2s 583us/step - loss: 102.2724 - mean_squared_error: 102.2724 - val_loss: 105.4589 - val_mean_squared_error: 105.4589\n",
            "Epoch 53/100\n",
            "4000/4000 [==============================] - 2s 575us/step - loss: 100.8547 - mean_squared_error: 100.8547 - val_loss: 104.3965 - val_mean_squared_error: 104.3965\n",
            "Epoch 54/100\n",
            "4000/4000 [==============================] - 2s 583us/step - loss: 102.5747 - mean_squared_error: 102.5747 - val_loss: 103.2326 - val_mean_squared_error: 103.2326\n",
            "Epoch 55/100\n",
            "4000/4000 [==============================] - 2s 585us/step - loss: 99.4938 - mean_squared_error: 99.4938 - val_loss: 102.6495 - val_mean_squared_error: 102.6495\n",
            "Epoch 56/100\n",
            "4000/4000 [==============================] - 2s 585us/step - loss: 99.6951 - mean_squared_error: 99.6951 - val_loss: 107.6858 - val_mean_squared_error: 107.6858\n",
            "Epoch 57/100\n",
            "4000/4000 [==============================] - 2s 581us/step - loss: 100.3071 - mean_squared_error: 100.3071 - val_loss: 103.7272 - val_mean_squared_error: 103.7272\n",
            "Epoch 58/100\n",
            "4000/4000 [==============================] - 2s 576us/step - loss: 97.8055 - mean_squared_error: 97.8055 - val_loss: 101.4109 - val_mean_squared_error: 101.4109\n",
            "Epoch 59/100\n",
            "4000/4000 [==============================] - 2s 579us/step - loss: 98.2248 - mean_squared_error: 98.2248 - val_loss: 102.4853 - val_mean_squared_error: 102.4853\n",
            "Epoch 60/100\n",
            "4000/4000 [==============================] - 2s 583us/step - loss: 98.4465 - mean_squared_error: 98.4465 - val_loss: 100.8224 - val_mean_squared_error: 100.8224\n",
            "Epoch 61/100\n",
            "4000/4000 [==============================] - 2s 584us/step - loss: 96.6036 - mean_squared_error: 96.6036 - val_loss: 102.1833 - val_mean_squared_error: 102.1833\n",
            "Epoch 62/100\n",
            "4000/4000 [==============================] - 2s 576us/step - loss: 97.0610 - mean_squared_error: 97.0610 - val_loss: 107.2386 - val_mean_squared_error: 107.2386\n",
            "Epoch 63/100\n",
            "4000/4000 [==============================] - 2s 584us/step - loss: 98.1794 - mean_squared_error: 98.1794 - val_loss: 102.1092 - val_mean_squared_error: 102.1092\n",
            "Epoch 64/100\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 94.5497 - mean_squared_error: 94.5497 - val_loss: 100.3149 - val_mean_squared_error: 100.3149\n",
            "Epoch 65/100\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 96.1560 - mean_squared_error: 96.1560 - val_loss: 99.0440 - val_mean_squared_error: 99.0440\n",
            "Epoch 66/100\n",
            "4000/4000 [==============================] - 2s 580us/step - loss: 94.9430 - mean_squared_error: 94.9430 - val_loss: 97.9977 - val_mean_squared_error: 97.9977\n",
            "Epoch 67/100\n",
            "4000/4000 [==============================] - 2s 579us/step - loss: 94.1366 - mean_squared_error: 94.1366 - val_loss: 98.6577 - val_mean_squared_error: 98.6577\n",
            "Epoch 68/100\n",
            "4000/4000 [==============================] - 2s 562us/step - loss: 93.7541 - mean_squared_error: 93.7541 - val_loss: 105.0367 - val_mean_squared_error: 105.0367\n",
            "Epoch 69/100\n",
            "4000/4000 [==============================] - 2s 582us/step - loss: 94.2267 - mean_squared_error: 94.2267 - val_loss: 98.9572 - val_mean_squared_error: 98.9572\n",
            "Epoch 70/100\n",
            "4000/4000 [==============================] - 2s 581us/step - loss: 94.1748 - mean_squared_error: 94.1748 - val_loss: 96.8524 - val_mean_squared_error: 96.8524\n",
            "Epoch 71/100\n",
            "4000/4000 [==============================] - 2s 582us/step - loss: 92.0180 - mean_squared_error: 92.0180 - val_loss: 97.8471 - val_mean_squared_error: 97.8471\n",
            "Epoch 72/100\n",
            "4000/4000 [==============================] - 2s 573us/step - loss: 92.1562 - mean_squared_error: 92.1562 - val_loss: 95.9092 - val_mean_squared_error: 95.9092\n",
            "Epoch 73/100\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 91.5060 - mean_squared_error: 91.5060 - val_loss: 98.2420 - val_mean_squared_error: 98.2420\n",
            "Epoch 74/100\n",
            "4000/4000 [==============================] - 2s 584us/step - loss: 91.8050 - mean_squared_error: 91.8050 - val_loss: 95.3776 - val_mean_squared_error: 95.3776\n",
            "Epoch 75/100\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 91.3137 - mean_squared_error: 91.3137 - val_loss: 96.8990 - val_mean_squared_error: 96.8990\n",
            "Epoch 76/100\n",
            "4000/4000 [==============================] - 2s 580us/step - loss: 90.6244 - mean_squared_error: 90.6244 - val_loss: 103.3263 - val_mean_squared_error: 103.3263\n",
            "Epoch 77/100\n",
            "4000/4000 [==============================] - 2s 568us/step - loss: 92.0974 - mean_squared_error: 92.0974 - val_loss: 101.0929 - val_mean_squared_error: 101.0929\n",
            "Epoch 78/100\n",
            "4000/4000 [==============================] - 2s 572us/step - loss: 88.4260 - mean_squared_error: 88.4260 - val_loss: 94.5954 - val_mean_squared_error: 94.5954\n",
            "Epoch 79/100\n",
            "4000/4000 [==============================] - 2s 572us/step - loss: 89.6435 - mean_squared_error: 89.6435 - val_loss: 107.2424 - val_mean_squared_error: 107.2424\n",
            "Epoch 80/100\n",
            "4000/4000 [==============================] - 2s 575us/step - loss: 90.4058 - mean_squared_error: 90.4058 - val_loss: 93.7516 - val_mean_squared_error: 93.7516\n",
            "Epoch 81/100\n",
            "4000/4000 [==============================] - 2s 567us/step - loss: 87.7188 - mean_squared_error: 87.7188 - val_loss: 92.8736 - val_mean_squared_error: 92.8736\n",
            "Epoch 82/100\n",
            "4000/4000 [==============================] - 2s 574us/step - loss: 88.6829 - mean_squared_error: 88.6829 - val_loss: 92.9149 - val_mean_squared_error: 92.9149\n",
            "Epoch 83/100\n",
            "4000/4000 [==============================] - 2s 566us/step - loss: 88.0036 - mean_squared_error: 88.0036 - val_loss: 92.2308 - val_mean_squared_error: 92.2308\n",
            "Epoch 84/100\n",
            "4000/4000 [==============================] - 2s 569us/step - loss: 87.5074 - mean_squared_error: 87.5074 - val_loss: 95.2571 - val_mean_squared_error: 95.2571\n",
            "Epoch 85/100\n",
            "4000/4000 [==============================] - 2s 567us/step - loss: 89.6428 - mean_squared_error: 89.6428 - val_loss: 95.2685 - val_mean_squared_error: 95.2685\n",
            "Epoch 86/100\n",
            "4000/4000 [==============================] - 2s 572us/step - loss: 85.4864 - mean_squared_error: 85.4864 - val_loss: 91.5837 - val_mean_squared_error: 91.5836\n",
            "Epoch 87/100\n",
            "4000/4000 [==============================] - 2s 578us/step - loss: 86.2902 - mean_squared_error: 86.2902 - val_loss: 122.3263 - val_mean_squared_error: 122.3263\n",
            "Epoch 88/100\n",
            "4000/4000 [==============================] - 2s 577us/step - loss: 87.0890 - mean_squared_error: 87.0890 - val_loss: 92.7927 - val_mean_squared_error: 92.7927\n",
            "Epoch 89/100\n",
            "4000/4000 [==============================] - 2s 574us/step - loss: 85.5497 - mean_squared_error: 85.5497 - val_loss: 91.9536 - val_mean_squared_error: 91.9536\n",
            "Epoch 90/100\n",
            "4000/4000 [==============================] - 2s 563us/step - loss: 86.9079 - mean_squared_error: 86.9079 - val_loss: 92.7964 - val_mean_squared_error: 92.7964\n",
            "Epoch 91/100\n",
            "4000/4000 [==============================] - 2s 567us/step - loss: 84.2509 - mean_squared_error: 84.2509 - val_loss: 97.4593 - val_mean_squared_error: 97.4593\n",
            "Epoch 92/100\n",
            "4000/4000 [==============================] - 2s 565us/step - loss: 85.0745 - mean_squared_error: 85.0745 - val_loss: 90.5237 - val_mean_squared_error: 90.5237\n",
            "Epoch 93/100\n",
            "4000/4000 [==============================] - 2s 570us/step - loss: 85.3626 - mean_squared_error: 85.3626 - val_loss: 100.1727 - val_mean_squared_error: 100.1727\n",
            "Epoch 94/100\n",
            "4000/4000 [==============================] - 2s 565us/step - loss: 84.4955 - mean_squared_error: 84.4955 - val_loss: 89.5586 - val_mean_squared_error: 89.5586\n",
            "Epoch 95/100\n",
            "4000/4000 [==============================] - 2s 565us/step - loss: 84.8589 - mean_squared_error: 84.8589 - val_loss: 91.3956 - val_mean_squared_error: 91.3956\n",
            "Epoch 96/100\n",
            "4000/4000 [==============================] - 2s 567us/step - loss: 82.4840 - mean_squared_error: 82.4840 - val_loss: 89.3981 - val_mean_squared_error: 89.3981\n",
            "Epoch 97/100\n",
            "4000/4000 [==============================] - 2s 567us/step - loss: 83.8169 - mean_squared_error: 83.8169 - val_loss: 88.8380 - val_mean_squared_error: 88.8380\n",
            "Epoch 98/100\n",
            "4000/4000 [==============================] - 2s 571us/step - loss: 84.2892 - mean_squared_error: 84.2892 - val_loss: 89.0220 - val_mean_squared_error: 89.0220\n",
            "Epoch 99/100\n",
            "4000/4000 [==============================] - 2s 569us/step - loss: 83.5175 - mean_squared_error: 83.5175 - val_loss: 90.2616 - val_mean_squared_error: 90.2616\n",
            "Epoch 100/100\n",
            "4000/4000 [==============================] - 2s 566us/step - loss: 81.8728 - mean_squared_error: 81.8728 - val_loss: 88.2246 - val_mean_squared_error: 88.2246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF7ZntmEqtAV",
        "colab_type": "text"
      },
      "source": [
        "## Calculating MSE\n",
        "The loss function that we will use to train the model will be **MSE**, or **mean squared error**, which is simply defined as:\n",
        "\n",
        "$ \\text{MSE } =  \\frac{1}{n}\\sum^n_{i=1}(\\mathbf{\\hat{Y}}-\\mathbf{Y})^2$\n",
        "\n",
        "Where $\\mathbf{\\hat{Y}}$ is the predicted image matrix and $\\mathbf{Y}$ is the true image matrix, and we do elementwise matrix subtraction. $n$ is simple the number of data points, which in our case would be\n",
        "\n",
        "$n = \\text{# Images} \\times \\text{Pixel Res}^2 \\times \\text{# Channels}$\n",
        "\n",
        "So for example, our test set contains 1000 RGB images that are 128x128 pixels with 3 channels per image (RGB), giving us $n = 49,152,000$. Now, for convenience, let us create a function called ```MSE(Predict = , True = , n = )```, where ```Predict``` is the model output, ```True``` is the original image, and ```n``` is the number of images. We want the output to just be the MSE.\n",
        "\n",
        "## Calculate PSNR\n",
        "Peak signal-to-noise ratio (PSNR) is the standard measurement used to gauge how effective an image upscaling method is. We cannot use this function as our loss function for our neural network however, since the loss function must be differentiable. With that being said, we still want to calculate this on our test dataset after the model is trained. The formula for PSNR is\n",
        "\n",
        "$ \\text{PSNR} = 10\\cdot\\text{log}_{10}\\left(\\frac{\\text{MAX}^2_I}{\\text{MSE}} \\right) $\n",
        "\n",
        "Where $\\text{MAX}^2_I$ is the maximum possible pixel value for the image. Since our images are stored as uint8, the maximum value is $\\text{MAX}^2_I = 256^2 = 65536$. Now, for convenience, let us create a function called ```PSNR(MSE = , MAX = )```, where ```MSE``` is the input MSE and ```MAX``` is the maximum pixel value, which in this case is 256. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpTqV3WbG8tC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def MSE(Predict,Actual,n):\n",
        "  differences = np.subtract(Predict, Actual)\n",
        "  Result = (np.sum(np.power(differences,2))) / n\n",
        "  return Result\n",
        "\n",
        "def PSNR(MSE,MAX):\n",
        "  Result = 10 * np.log10((MAX^2)/MSE)\n",
        "  return Result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RijOpHgNbgQ",
        "colab_type": "text"
      },
      "source": [
        "## Generating Baseline Images for Evaluation\n",
        "Now, we want to create two new NumPy arrays. While we can find the MSE and PSNR of our model, there is no good way to measure its relative performance until we compare it to other baseline methods. We will create a NumPy array called ```RawLR``` that contains the 32x32 image upscaled to 128x128 without any interpolation or upscaling methods (ie. every pixel in the 32x32 is basically duplicated into a 4x4 to generate the 128x128). We will also create a NumPy array called ```Bicubic``` that contains the 32x32 image upscaled to 128x128 via bicubic interpolation. In the code below, I show you how this is performed on a single image, but we need to generate the 4D NumPy array containing all of the test images from ```TestIn```. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W69HOutNOc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "\n",
        "# No interpolation example\n",
        "NoInterp_Control = []\n",
        "for i in range(len(TestIn)):\n",
        "  NormalExample = np.zeros([128,128,3])\n",
        "  NormalExample = rescale(TestIn[i,:,:,:], (4,4,1), order = 0, anti_aliasing=False)\n",
        "  NoInterp_Control.append(NormalExample)\n",
        "#cv2_imshow(NoInterp_Control[2])\n",
        "\n",
        "# Bicubic interpolation example (loop j = 3 for RGB channels)\n",
        "BiCubic_Control = []\n",
        "for i in range(len(TestIn)):\n",
        "  BicubicExample = np.zeros([128,128,3])\n",
        "  for j in range(3):\n",
        "    BicubicExample[:,:,j] = cv2.resize(TestIn[i,:,:,j], dsize = (128,128), interpolation = cv2.INTER_CUBIC)\n",
        "  BiCubic_Control.append(BicubicExample)\n",
        "\n",
        "#cv2_imshow(BicubicExample)\n",
        "#cv2_imshow(BiCubic_Control[11])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Slp1PnEcOt7M",
        "colab_type": "text"
      },
      "source": [
        "## Calculate MSE and PSNR of Raw Images, Bicubic Images, and FSRCNN Images\n",
        "By the time you reach this section, you have already created functions for calculating MSE and PSNR. In addition, you have generated the three NumPy arrays for each of the three methods (no interpolation, bicubic, and FSRCNN images). Now the simple put is inputting these NumPy arrays to calculate the MSE and PSNR of each of these methods so that we can see how well the FSRCNN is performing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrhBhrbbt5HR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "bf177875-34a3-4f22-c5d6-7284088e00a9"
      },
      "source": [
        "# Calculate the MSE and PSNR of images with no interpolation \n",
        "print('Raw Image MSE:')\n",
        "n = MSE(NoInterp_Control,TestOut,len(TestOut))\n",
        "print(n)\n",
        "print('Raw Image PSNR:')\n",
        "n = PSNR(n,256)\n",
        "print(n)\n",
        "\n",
        "# Calculate the MSE and PSNR of images with bicubic interpolation\n",
        "print('\\nBicubic Image MSE:')\n",
        "n = MSE(BiCubic_Control,TestOut,len(TestOut))\n",
        "print(n)\n",
        "print('Bicubic Image PSNR:')\n",
        "n = PSNR(n,256)\n",
        "print(n)\n",
        "\n",
        "# Calculate the MSE and PSNR of images with FSRCNN\n",
        "print('\\nFSRCNN Image MSE:')\n",
        "n = MSE(ModelOut,TestOut,len(TestOut))\n",
        "print(n)\n",
        "print('FSRCNN Image PSNR:')\n",
        "n = PSNR(n,256)\n",
        "print(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Raw Image MSE:\n",
            "19912906.6565625\n",
            "Raw Image PSNR:\n",
            "-48.87514951993367\n",
            "\n",
            "Bicubic Image MSE:\n",
            "12370807.549792508\n",
            "Bicubic Image PSNR:\n",
            "-46.8077834475493\n",
            "\n",
            "FSRCNN Image MSE:\n",
            "4336414.517288307\n",
            "FSRCNN Image PSNR:\n",
            "-42.255110837032916\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}